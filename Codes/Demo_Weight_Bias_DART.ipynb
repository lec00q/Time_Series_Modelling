{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe7fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ashwini.kumar\\source\\repos\\anaconda3\\envs\\practice\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ashwini.kumar\\source\\repos\\anaconda3\\envs\\practice\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ashwini.kumar\\source\\repos\\anaconda3\\envs\\practice\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ashwini.kumar\\source\\repos\\anaconda3\\envs\\practice\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ashwini.kumar\\source\\repos\\anaconda3\\envs\\practice\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb177dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/ashwini.kumar/Downloads/AirPassengers.csv')\n",
    "\n",
    "Series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfed50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeries, specifying the time and value columns\n",
    "series = TimeSeries.from_dataframe(df, 'Month', '#Passengers')\n",
    "\n",
    "# Set aside the last 36 months as a validation series\n",
    "train_data, val_data = series[:-36], series[-36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b49a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First We will try the DART Model and see how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc873940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NBEATSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33d07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model object\n",
    "model = NBEATSModel(input_chunk_length=24 , output_chunk_length=12, n_epochs = 2 , random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc56e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:19:23,183] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:19:23,183] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:19:23,258] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:23,258] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:23,259] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:19:23,259] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.575    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.11it/s, loss=1.93e+04]\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "model = model.fit(train_data, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43642018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 3it [00:00, ?it/s]\n",
      "Mape = 17.55%\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from darts.metrics import mape\n",
    "\n",
    "pred_air = model.predict(n = 36, series = train_data)\n",
    "\n",
    "\n",
    "print(\"Mape = {:.2f}%\".format(mape(val_data , pred_air)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e430427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mape = 17.55%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mape = {:.2f}%\".format(mape(val_data , pred_air)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0d21466",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8e4dc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19388\\2366315092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9690f9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_201931-apli5uc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/apli5uc0\" target=\"_blank\">misty-breeze-48</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init()  \n",
    "wandb.log({'accuracy_score': mape(val_data , pred_air)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99802a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: xmja2gsn\n",
      "Sweep URL: https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\n",
      "{'method': 'random',\n",
      " 'name': 'my-sweep',\n",
      " 'parameters': {'input_chunk_length': {'values': [18, 24, 30, 36]},\n",
      "                'n_epochs': {'values': [10, 20, 50]},\n",
      "                'output_chunk_length': {'values': [9, 12, 15, 18]}}}\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "  \"name\" : \"my-sweep\",\n",
    "  \"method\" : \"random\",\n",
    "  \"parameters\" : {\n",
    "    \"n_epochs\" : {\n",
    "      \"values\" : [10, 20, 50]\n",
    "    },\n",
    "      \"input_chunk_length\" : {\"values\" : [18,24,30,36]},\n",
    "      \"output_chunk_length\" : {\"values\" : [9,12,15,18]}\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3933f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l6tjito8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_chunk_length: 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_chunk_length: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_201940-l6tjito8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/l6tjito8\" target=\"_blank\">faithful-sweep-1</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:19:43,672] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:19:43,672] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:19:43,749] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:43,749] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:43,751] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:19:43,751] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.64it/s, loss=1.28e+03]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:19:49,397] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:19:49,397] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:19:49,490] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:49,490] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:19:49,492] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:19:49,492] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.38it/s, loss=328]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:20:00,909] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:20:00,909] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:20:01,010] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:20:01,010] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:20:01,012] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:20:01,012] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.66it/s, loss=183]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:20:20,617] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:20:20,617] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:20:20,754] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:20:20,754] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:20:20,756] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:20:20,756] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.74it/s, loss=158]\n",
      "Predicting: 3it [00:00, ?it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>▅█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>15.06833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">faithful-sweep-1</strong>: <a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/l6tjito8\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/runs/l6tjito8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220317_201940-l6tjito8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c7rzkygc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_chunk_length: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_chunk_length: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_202101-c7rzkygc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/c7rzkygc\" target=\"_blank\">generous-sweep-2</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:04,123] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:04,123] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:04,224] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:04,224] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:04,225] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:21:04,225] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.30it/s, loss=1.64e+03]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:09,617] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:09,617] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:09,771] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:09,771] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:09,773] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:21:09,773] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.66it/s, loss=451]\n",
      "Predicting: 3it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:25,840] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:25,840] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:26,013] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:26,013] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:26,015] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:21:26,015] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.11it/s, loss=273]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:45,334] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n",
      "[2022-03-17 20:21:45,334] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 70 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:21:45,421] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:45,421] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:21:45,422] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:21:45,422] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.579    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.01it/s, loss=199]\n",
      "Predicting: 3it [00:00, ?it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>▄▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>16.40702</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-sweep-2</strong>: <a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/c7rzkygc\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/runs/c7rzkygc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220317_202101-c7rzkygc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mhnpjj1h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_chunk_length: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_chunk_length: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_202222-mhnpjj1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/mhnpjj1h\" target=\"_blank\">lyric-sweep-3</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:22:25,136] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:22:25,136] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:22:25,214] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:25,214] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:25,214] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:22:25,214] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.584    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.15it/s, loss=1.75e+03]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:22:30,953] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:22:30,953] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:22:31,035] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:31,035] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:31,051] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:22:31,051] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.584    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.26it/s, loss=598]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:22:43,245] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:22:43,245] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:22:43,347] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:43,347] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:22:43,348] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:22:43,348] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.584    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.08it/s, loss=362]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:23:01,138] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:23:01,138] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 67 samples.\n",
      "[2022-03-17 20:23:01,212] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:23:01,212] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:23:01,227] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:23:01,227] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.584    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.31it/s, loss=278]\n",
      "Predicting: 3it [00:00, ?it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>▂▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>18.80386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lyric-sweep-3</strong>: <a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/mhnpjj1h\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/runs/mhnpjj1h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220317_202222-mhnpjj1h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z4c38ke6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_chunk_length: 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_chunk_length: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_202338-z4c38ke6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/z4c38ke6\" target=\"_blank\">rosy-sweep-4</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:23:44,148] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:23:44,148] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:23:44,219] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:23:44,219] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:23:44,221] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:23:44,221] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.01it/s, loss=1.28e+03]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:23:50,526] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:23:50,526] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:23:50,615] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:23:50,615] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:23:50,615] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:23:50,615] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.65it/s, loss=328]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:24:03,221] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:24:03,221] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:24:03,325] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:24:03,325] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:24:03,327] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:24:03,327] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.82it/s, loss=183]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:24:22,556] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n",
      "[2022-03-17 20:24:22,556] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 82 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:24:22,663] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:24:22,663] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:24:22,664] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:24:22,664] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.1 M \n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.1 M     Total params\n",
      "49.193    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.39it/s, loss=158]\n",
      "Predicting: 3it [00:00, ?it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>▅█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>15.06833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-sweep-4</strong>: <a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/z4c38ke6\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/runs/z4c38ke6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220317_202338-z4c38ke6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cj4re13o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_chunk_length: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toutput_chunk_length: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ashwini.kumar\\wandb\\run-20220317_202509-cj4re13o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/cj4re13o\" target=\"_blank\">splendid-sweep-5</a></strong> to <a href=\"https://wandb.ai/fibonacciash/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/sweeps/xmja2gsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:12,316] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:25:12,316] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:25:12,380] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:12,380] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:12,381] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:25:12,381] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.575    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  5.55it/s, loss=1.46e+03]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:17,866] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:25:17,866] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:18,336] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:18,336] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:18,337] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:25:18,337] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.575    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.78it/s, loss=361]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:30,682] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:25:30,682] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:30,787] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:30,787] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:30,789] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:25:30,789] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.575    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.99it/s, loss=205]\n",
      "Predicting: 3it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:49,999] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n",
      "[2022-03-17 20:25:49,999] INFO | darts.models.forecasting.torch_forecasting_model | Train dataset contains 73 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-17 20:25:50,114] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:50,114] INFO | darts.models.forecasting.torch_forecasting_model | Time series values are 64-bits; casting model to float64.\n",
      "[2022-03-17 20:25:50,115] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "[2022-03-17 20:25:50,115] WARNING | darts.models.forecasting.torch_forecasting_model | DeprecationWarning: kwarg `verbose` is deprecated and will be removed in a future Darts version. Instead, control verbosity with PyTorch Lightning Trainer parameters `enable_progress_bar`, `progress_bar_refresh_rate` and `enable_model_summary` in the `pl_trainer_kwargs` dict at model creation.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | MSELoss    | 0     \n",
      "1 | stacks    | ModuleList | 6.2 M \n",
      "-----------------------------------------\n",
      "6.2 M     Trainable params\n",
      "1.4 K     Non-trainable params\n",
      "6.2 M     Total params\n",
      "49.575    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.00it/s, loss=179]\n",
      "Predicting: 3it [00:00, ?it/s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>loss</td><td>█▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>13.174</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-sweep-5</strong>: <a href=\"https://wandb.ai/fibonacciash/uncategorized/runs/cj4re13o\" target=\"_blank\">https://wandb.ai/fibonacciash/uncategorized/runs/cj4re13o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220317_202509-cj4re13o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train():\n",
    "    with wandb.init() as run:\n",
    "        config = wandb.config\n",
    "\n",
    "       \n",
    " # your model training code here\n",
    "        for epoch in [80,120]:\n",
    "            model = NBEATSModel(input_chunk_length=config.input_chunk_length , output_chunk_length=config.output_chunk_length,\n",
    "                                n_epochs = epoch,\n",
    "                            random_state = 15)\n",
    "            \n",
    "            # fitting the model\n",
    "            model_req = model.fit(train_data, verbose = True)\n",
    "            \n",
    "            pred_air = model_req.predict(n = 58, series = train_data)\n",
    "\n",
    "\n",
    "            loss = mape(val_data , pred_air)\n",
    "            wandb.log({\"loss\": loss, \"epoch\": epoch})           \n",
    "\n",
    "count = 5 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e88af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
